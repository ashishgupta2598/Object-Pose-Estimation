# Object-Pose-Estimation
As the data contatins too many files and its difficult to upload all, So i created a .npy folder.Link below in the text.
Training_Label(Target) Data----https://drive.google.com/open?id=11oIPnNgjuyreib2hvoDPoQYYtOtBRpAB
Training_Images---https://drive.google.com/open?id=1gOaDUXZZAKImdNlMdjWtj3cjj9o4Q1Cw


Original Dataset Links-
ShapeNet rendered images http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz

In the Original Dataset the rendering parameters are given. In each rendering folder, there is a metadata file for all images. Each row describes the parameters for an image. The first three numbers are pitch, roll, yaw, the fourth number is the distance between the center of the object and the camera. The fifth number is half of the camera FOV.Here as the images are CAD designed so translation is 0(tx,ty,tz).



![oie_1yR1kSNeiNa5](https://user-images.githubusercontent.com/40520042/64719962-fe911b80-d4e6-11e9-88c0-6b941905de53.png)
